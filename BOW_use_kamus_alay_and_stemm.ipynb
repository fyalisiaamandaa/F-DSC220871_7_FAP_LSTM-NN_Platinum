{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni2epbNkEbJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682bc08a-4841-437d-d48a-ab795aac5c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySastrawi\n",
            "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/210.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install PySastrawi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import sklearn\n",
        "import keras\n",
        "import pickle\n",
        "import tensorflow.keras as keras\n",
        "import collections\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.regularizers import L1L2\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "#from terbilang import Terbilang\n",
        "\n",
        "#t = Terbilang()\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('all')"
      ],
      "metadata": {
        "id": "qB32hDdmEb_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to print complete sentence\n",
        "pd.options.display.max_colwidth = 500"
      ],
      "metadata": {
        "id": "RGIdWW6tEcCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kamus\n",
        "kamusalay = pd.read_csv('new_kamusalay.csv', encoding =  'ISO-8859-1', names=['old','new'])\n",
        "kamusalay.head()"
      ],
      "metadata": {
        "id": "eQcCGCyGEcFM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "97039617-6736-4067-c16a-93ac1898e0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   old                       new\n",
              "0  anakjakartaasikasik  anak jakarta asyik asyik\n",
              "1         pakcikdahtua         pak cik sudah tua\n",
              "2       pakcikmudalagi         pak cik muda lagi\n",
              "3          t3tapjokowi              tetap jokowi\n",
              "4                   3x                 tiga kali"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-925b8f27-e15c-473d-b5d1-e82260fc085d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>old</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>anakjakartaasikasik</td>\n",
              "      <td>anak jakarta asyik asyik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pakcikdahtua</td>\n",
              "      <td>pak cik sudah tua</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pakcikmudalagi</td>\n",
              "      <td>pak cik muda lagi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>t3tapjokowi</td>\n",
              "      <td>tetap jokowi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3x</td>\n",
              "      <td>tiga kali</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-925b8f27-e15c-473d-b5d1-e82260fc085d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-925b8f27-e15c-473d-b5d1-e82260fc085d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-925b8f27-e15c-473d-b5d1-e82260fc085d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"train_preprocess.tsv.txt\"\n",
        "df = pd.read_csv(file_path, delimiter='\\t', names=[\"Tweet\", \"Sentimen\"])\n",
        "#print(type(df[\"data\"]))\n",
        "#print(df[\"data\"])"
      ],
      "metadata": {
        "id": "4Y2i0SCeEcH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_data(text):\n",
        "    text = text.lower()\n",
        "    text=re.sub('url', '', text)\n",
        "    text = re.sub('url\\S+', '', text)\n",
        "    text=re.sub('http', '', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    #text = re.sub(r'&', 'dan', text)\n",
        "    #text=re.sub(r'/', 'atau', text)\n",
        "    #text = re.sub(r'&amp', 'dan', text)\n",
        "    #text = re.sub(r'&lt;', '', text)\n",
        "    #text = re.sub(r'&gt;', '', text)\n",
        "    text = re.sub(r'%', ' persen', text)\n",
        "    text = re.sub(r' {2,}', ' ', text)\n",
        "    text=re.sub(r'(\\\\x(.){2})', '', text) #emoticon\n",
        "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "0GeU_44IEcKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words\n",
        "def stemmingText(text):\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    text = stemmer.stem(text)\n",
        "    #text = [stemmer.stem(word) for word in text]\n",
        "    return text\n",
        "\n",
        "#Convert list of words into sentence\n",
        "#def toSentence(list_words):\n",
        "#    sentence = ' '.join(word for word in list_words)\n",
        "#    return sentence"
      ],
      "metadata": {
        "id": "X_I1m3KgEcNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data\n",
        "def convert(lst):\n",
        "    return ''.join(lst).split()"
      ],
      "metadata": {
        "id": "JCeE9ClcEoNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check with kamus alay\n",
        "def filter_data(text):\n",
        "        result = \"\"\n",
        "        tweets = text\n",
        "        #print(tweets)\n",
        "        temp=[]\n",
        "        for tweet in tweets:\n",
        "            try:\n",
        "                trying = np.where(kamusalay['old']==tweet)[0][0]\n",
        "                tweet = kamusalay['new'].iloc[trying]\n",
        "            except:\n",
        "                tweet = tweet\n",
        "            #print(tweet)\n",
        "            temp.append(tweet)\n",
        "            result = result + \" \" + tweet\n",
        "        return result"
      ],
      "metadata": {
        "id": "6DV4dnObEoQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ReviewTweet'] = df['Tweet'].apply(cleaning_data)\n",
        "df['ReviewTweet']=df['ReviewTweet'].apply(convert)\n",
        "df['ReviewTweet']=df['ReviewTweet'].apply(filter_data)\n",
        "df['ReviewTweet'] = df['ReviewTweet'].apply(stemmingText)"
      ],
      "metadata": {
        "id": "ejeHmUzLEtfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "69XWLSOfEtiA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "23b2f702-9ad7-4a33-a0d2-cc7cffad3bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                  Tweet  \\\n",
              "0  warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !   \n",
              "1                                                                                                                                                                                                                                                                                                                mohon ulama lurus dan k212 mmbri hujjah partai apa yang harus diwlh agar suara islam tidak pecah-pecah   \n",
              "2                                                                                                                                                                                                                              lokasi strategis di jalan sumatera bandung . tempat nya nyaman terutama sofa di lantai 2 . paella nya enak , sangat pas dimakan dengan minum bir dingin . appetiser nya juga enak-enak .   \n",
              "3                                                                                                                                                                                                                                                                                                                         betapa bahagia nya diri ini saat unboxing paket dan barang nya bagus ! menetapkan beli lagi !   \n",
              "4                                                                                                                                                                                                duh . jadi mahasiswa jangan sombong dong . kasih kartu kuning segala . belajar dulu yang baik , tidak usahlah ikut-ikut politik . nanti sudah selesai kuliah nya mau ikut politik juga tidak telat . dasar mahasiswa .   \n",
              "\n",
              "   Sentimen  \\\n",
              "0  positive   \n",
              "1   neutral   \n",
              "2  positive   \n",
              "3  positive   \n",
              "4  negative   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                     ReviewTweet  \n",
              "0  warung ini milik oleh usaha pabrik tahu yang sudah puluh tahun kenal buat tahu putih di bandung tahu kualitas padu ahli masak padu kretivitas jadi warung yang saji menu utama bahan tahu tambah menu umum lain seperti ayam semua selera indonesia harga cukup jangkau jangan lewat tahu bletoka nya tidak kalah dengan yang asli dari tegal  \n",
              "1                                                                                                                                                                                                                                         mohon ulama lurus dan k212 mmbri hujjah partai apa yang harus diwlh agar suara islam tidak pecah pecah  \n",
              "2                                                                                                                                                                       lokasi strategis di jalan sumatra bandung tempat nya nyaman utama sofa di lantai 2 paella nya enak sangat pas makan dengan minum bir dingin appetiser nya juga enak enak  \n",
              "3                                                                                                                                                                                                                                                           betapa bahagia nya diri ini saat unboxing paket dan barang nya bagus tetap beli lagi  \n",
              "4                                                                                                                                            aduh jadi mahasiswa jangan sombong dong kasih kartu kuning segala ajar dulu yang baik tidak usah ikut ikut politik nanti sudah selesai kuliah nya mau ikut politik juga tidak telat dasar mahasiswa  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3d241ff-14e6-41eb-ab43-431b33aed35e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Sentimen</th>\n",
              "      <th>ReviewTweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !</td>\n",
              "      <td>positive</td>\n",
              "      <td>warung ini milik oleh usaha pabrik tahu yang sudah puluh tahun kenal buat tahu putih di bandung tahu kualitas padu ahli masak padu kretivitas jadi warung yang saji menu utama bahan tahu tambah menu umum lain seperti ayam semua selera indonesia harga cukup jangkau jangan lewat tahu bletoka nya tidak kalah dengan yang asli dari tegal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mohon ulama lurus dan k212 mmbri hujjah partai apa yang harus diwlh agar suara islam tidak pecah-pecah</td>\n",
              "      <td>neutral</td>\n",
              "      <td>mohon ulama lurus dan k212 mmbri hujjah partai apa yang harus diwlh agar suara islam tidak pecah pecah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lokasi strategis di jalan sumatera bandung . tempat nya nyaman terutama sofa di lantai 2 . paella nya enak , sangat pas dimakan dengan minum bir dingin . appetiser nya juga enak-enak .</td>\n",
              "      <td>positive</td>\n",
              "      <td>lokasi strategis di jalan sumatra bandung tempat nya nyaman utama sofa di lantai 2 paella nya enak sangat pas makan dengan minum bir dingin appetiser nya juga enak enak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>betapa bahagia nya diri ini saat unboxing paket dan barang nya bagus ! menetapkan beli lagi !</td>\n",
              "      <td>positive</td>\n",
              "      <td>betapa bahagia nya diri ini saat unboxing paket dan barang nya bagus tetap beli lagi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>duh . jadi mahasiswa jangan sombong dong . kasih kartu kuning segala . belajar dulu yang baik , tidak usahlah ikut-ikut politik . nanti sudah selesai kuliah nya mau ikut politik juga tidak telat . dasar mahasiswa .</td>\n",
              "      <td>negative</td>\n",
              "      <td>aduh jadi mahasiswa jangan sombong dong kasih kartu kuning segala ajar dulu yang baik tidak usah ikut ikut politik nanti sudah selesai kuliah nya mau ikut politik juga tidak telat dasar mahasiswa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3d241ff-14e6-41eb-ab43-431b33aed35e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3d241ff-14e6-41eb-ab43-431b33aed35e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3d241ff-14e6-41eb-ab43-431b33aed35e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use Bag of Words (BOW)\n",
        "data_preprocessed = df['ReviewTweet'].tolist()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(data_preprocessed)\n",
        "X = vectorizer.transform(data_preprocessed)\n",
        "X.toarray()[0].shape"
      ],
      "metadata": {
        "id": "slV8qczYEtky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedea40f-034a-4eac-cd95-35dfcfae6404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8476,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to save the model\n",
        "pickle.dump(vectorizer, open('featureBOW.p','wb'))"
      ],
      "metadata": {
        "id": "i_sXpCAeEtnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = df['Sentimen']"
      ],
      "metadata": {
        "id": "pAlaet4CEtp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data (with composition data train 80%, data test 20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size = 0.2)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "v1FApb3OEtsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "212c3332-265e-475e-bf1c-36d9722c119b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4196, 8476) (4196,)\n",
            "(1049, 8476) (1049,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLPClassifier(learning_rate='constant', learning_rate_init=0.001)\n",
        "model = model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "qsJGVuGaE4Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to save the model\n",
        "pickle.dump(model, open('model-sentimentBOW.p','wb'))"
      ],
      "metadata": {
        "id": "FUN2xU0gE4Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = model.predict(X_test)\n",
        "\n",
        "print(classification_report(test, y_test))"
      ],
      "metadata": {
        "id": "q9jdHI1jE4OO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "y = classes\n",
        "\n",
        "for iteration, data in enumerate(kf.split(X), start=1):\n",
        "  data_train = X[data[0]]\n",
        "  target_train = y[data[0]]\n",
        "\n",
        "  data_test = X[data[1]]\n",
        "  target_test = y[data[1]]\n",
        "\n",
        "  clf = MLPClassifier(learning_rate='constant', learning_rate_init=0.001)\n",
        "  clf.fit(data_train, target_train)\n",
        "\n",
        "  preds = clf.predict(data_test)\n",
        "\n",
        "  accuracy = accuracy_score(target_test, preds)\n",
        "\n",
        "  print(\"Training ke-\", iteration)\n",
        "  print(classification_report(target_test, preds))\n",
        "  print(\"_______________________________________\")\n",
        "\n",
        "  accuracies.append(accuracy)\n",
        "\n",
        "average_accuracy = np.mean(accuracies)\n",
        "\n",
        "print()\n",
        "print()\n",
        "print()\n",
        "print(\"Average accuracy :\", average_accuracy)"
      ],
      "metadata": {
        "id": "asRHciJNE4Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de2c683-83b8-4bc0-b9d4-7c0960c70e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ke- 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.80      0.80      0.80       680\n",
            "     neutral       0.77      0.66      0.71       239\n",
            "    positive       0.88      0.90      0.89      1281\n",
            "\n",
            "    accuracy                           0.85      2200\n",
            "   macro avg       0.82      0.79      0.80      2200\n",
            "weighted avg       0.84      0.85      0.84      2200\n",
            "\n",
            "_______________________________________\n",
            "Training ke- 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.81      0.78      0.79       706\n",
            "     neutral       0.71      0.70      0.70       220\n",
            "    positive       0.88      0.91      0.90      1274\n",
            "\n",
            "    accuracy                           0.84      2200\n",
            "   macro avg       0.80      0.79      0.80      2200\n",
            "weighted avg       0.84      0.84      0.84      2200\n",
            "\n",
            "_______________________________________\n",
            "Training ke- 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.79      0.78       682\n",
            "     neutral       0.78      0.67      0.72       215\n",
            "    positive       0.89      0.90      0.89      1303\n",
            "\n",
            "    accuracy                           0.84      2200\n",
            "   macro avg       0.81      0.78      0.80      2200\n",
            "weighted avg       0.84      0.84      0.84      2200\n",
            "\n",
            "_______________________________________\n",
            "Training ke- 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.79      0.81      0.80       698\n",
            "     neutral       0.78      0.66      0.72       229\n",
            "    positive       0.89      0.90      0.89      1273\n",
            "\n",
            "    accuracy                           0.85      2200\n",
            "   macro avg       0.82      0.79      0.80      2200\n",
            "weighted avg       0.85      0.85      0.85      2200\n",
            "\n",
            "_______________________________________\n",
            "Training ke- 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.76      0.84      0.80       670\n",
            "     neutral       0.78      0.67      0.72       245\n",
            "    positive       0.91      0.88      0.89      1285\n",
            "\n",
            "    accuracy                           0.85      2200\n",
            "   macro avg       0.82      0.80      0.80      2200\n",
            "weighted avg       0.85      0.85      0.85      2200\n",
            "\n",
            "_______________________________________\n",
            "\n",
            "\n",
            "\n",
            "Average accuracy : 0.8448181818181817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "original_text =  '''\n",
        "dia suka membaca buku tentang pengetahuan alam\n",
        "'''\n",
        "# Feature Extraction\n",
        "text = vectorizer.transform([cleaning_data(original_text)])\n",
        "\n",
        "#print(text) #0, 14410\n",
        "\n",
        "# predict the sentiment\n",
        "result = model.predict(text)[0]\n",
        "print(\"Sentiment:\")\n",
        "print()\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "Q92_BfIzFAlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cdbec87-9e9c-4afa-ba3e-bef91e5f346f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment:\n",
            "\n",
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "RPeCs9CzN4MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, test, labels=classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_1DHTMlcFAn-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}